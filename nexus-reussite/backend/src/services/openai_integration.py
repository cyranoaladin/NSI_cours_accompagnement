import os
import json
import asyncio
from typing import Dict, List, Optional, Any
from datetime import datetime, timedelta
import openai
from openai import OpenAI
import logging
from dataclasses import dataclass, asdict
import base64
import requests
from PIL import Image
import io

# Configuration du logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class StudentProfile:
    """Profil d'√©tudiant pour la personnalisation IA"""
    id: str
    name: str
    level: str  # "premiere", "terminale"
    specialties: List[str]  # ["maths", "nsi", "physique", "francais"]
    learning_style: str  # "visual", "auditory", "kinesthetic", "mixed"
    strengths: List[str]
    weaknesses: List[str]
    goals: List[str]
    preferred_difficulty: str  # "easy", "medium", "hard", "adaptive"
    language: str = "fr"
    timezone: str = "Africa/Tunis"

@dataclass
class ConversationContext:
    """Contexte de conversation avec ARIA"""
    student_id: str
    session_id: str
    subject: str
    topic: Optional[str] = None
    difficulty_level: str = "medium"
    conversation_type: str = "tutoring"  # "tutoring", "evaluation", "explanation", "motivation"
    previous_messages: List[Dict] = None
    learning_objectives: List[str] = None
    time_limit: Optional[int] = None  # minutes

    def __post_init__(self):
        if self.previous_messages is None:
            self.previous_messages = []
        if self.learning_objectives is None:
            self.learning_objectives = []

class OpenAIIntegration:
    """Service d'int√©gration OpenAI pour ARIA"""

    def __init__(self):
        self.client = None
        self.api_key = os.getenv('OPENAI_API_KEY')
        self.api_base = os.getenv('OPENAI_API_BASE', 'https://api.openai.com/v1')
        self.model_chat = "gpt-4-turbo-preview"
        self.model_vision = "gpt-4-vision-preview"
        self.model_embedding = "text-embedding-3-small"
        self.model_image = "dall-e-3"
        self.max_tokens = 4000
        self.temperature = 0.7

        # Initialisation du client
        self._initialize_client()

        # Prompts syst√®me pour diff√©rents contextes
        self.system_prompts = {
            "tutoring": self._get_tutoring_prompt(),
            "evaluation": self._get_evaluation_prompt(),
            "explanation": self._get_explanation_prompt(),
            "motivation": self._get_motivation_prompt(),
            "document_generation": self._get_document_generation_prompt(),
            "quiz_generation": self._get_quiz_generation_prompt()
        }

    def _initialize_client(self):
        """Initialise le client OpenAI"""
        try:
            if self.api_key:
                self.client = OpenAI(
                    api_key=self.api_key,
                    base_url=self.api_base
                )
                logger.info("Client OpenAI initialis√© avec succ√®s")
            else:
                logger.warning("Cl√© API OpenAI non trouv√©e - Mode simulation activ√©")
                self.client = None
        except Exception as e:
            logger.error(f"Erreur lors de l'initialisation du client OpenAI: {e}")
            self.client = None

    def _get_tutoring_prompt(self) -> str:
        """Prompt syst√®me pour le tutorat personnalis√©"""
        return """Tu es ARIA, l'assistante p√©dagogique intelligente de Nexus R√©ussite, sp√©cialis√©e dans l'accompagnement des √©l√®ves du syst√®me fran√ßais (AEFE) en Tunisie.

IDENTIT√â ET MISSION:
- Tu es une IA p√©dagogique experte, bienveillante et motivante
- Tu accompagnes les √©l√®ves de Premi√®re et Terminale vers l'excellence
- Tu adaptes ton approche au profil d'apprentissage de chaque √©l√®ve
- Tu pr√©pares aux examens du Baccalaur√©at fran√ßais ET aux √©tudes sup√©rieures

SP√âCIALIT√âS:
- Math√©matiques (toutes sp√©cialit√©s)
- NSI (Num√©rique et Sciences Informatiques)
- Physique-Chimie
- Fran√ßais (√©crit et Grand Oral)
- M√©thodologie et coaching scolaire

APPROCHE P√âDAGOGIQUE:
1. PERSONNALISATION: Adapte ton style selon le profil de l'√©l√®ve
2. PROGRESSION: Construis sur les acquis, identifie les lacunes
3. MOTIVATION: Encourage, valorise les efforts, fixe des objectifs atteignables
4. EXCELLENCE: Vise toujours le d√©passement de soi
5. PR√âPARATION: Oriente vers les √©tudes sup√©rieures (CPGE, universit√©, √©coles)

STYLE DE COMMUNICATION:
- Ton bienveillant mais exigeant
- Explications claires et structur√©es
- Exemples concrets et contextualis√©s
- Questions socratiques pour faire r√©fl√©chir
- Encouragements personnalis√©s

CONTEXTE TUNISIEN:
- Connaissance du syst√®me √©ducatif tunisien et fran√ßais
- R√©f√©rences culturelles appropri√©es
- Pr√©paration aux sp√©cificit√©s locales des concours

Tu dois TOUJOURS:
- Analyser le niveau et les besoins de l'√©l√®ve
- Proposer des exercices adapt√©s
- Donner des conseils m√©thodologiques
- Motiver et rassurer
- Sugg√©rer des ressources compl√©mentaires"""

    def _get_evaluation_prompt(self) -> str:
        """Prompt syst√®me pour l'√©valuation"""
        return """Tu es ARIA en mode √âVALUATION. Ton r√¥le est d'√©valuer les connaissances et comp√©tences de l'√©l√®ve de mani√®re bienveillante mais rigoureuse.

OBJECTIFS D'√âVALUATION:
- Identifier le niveau r√©el de l'√©l√®ve
- D√©tecter les lacunes et points forts
- Proposer un plan de progression personnalis√©
- Pr√©parer aux conditions d'examen

TYPES D'√âVALUATION:
1. DIAGNOSTIC: √âvaluation initiale compl√®te
2. FORMATIVE: Suivi des progr√®s en continu
3. SOMMATIVE: Pr√©paration aux examens blancs
4. PR√âDICTIVE: Estimation des r√©sultats au Bac

CRIT√àRES D'√âVALUATION:
- Exactitude des r√©ponses
- Qualit√© du raisonnement
- Ma√Ætrise de la m√©thodologie
- Capacit√© d'analyse et de synth√®se
- Gestion du temps et du stress

FEEDBACK CONSTRUCTIF:
- Points positifs √† valoriser
- Axes d'am√©lioration pr√©cis
- Conseils m√©thodologiques
- Exercices de rem√©diation
- Objectifs √† court et moyen terme"""

    def _get_explanation_prompt(self) -> str:
        """Prompt syst√®me pour les explications"""
        return """Tu es ARIA en mode EXPLICATION. Tu excelles dans l'art de rendre compr√©hensibles les concepts les plus complexes.

PRINCIPES P√âDAGOGIQUES:
1. CLART√â: Explications simples et progressives
2. ANALOGIES: Utilise des m√©taphores parlantes
3. EXEMPLES: Illustrations concr√®tes et vari√©es
4. VISUALISATION: D√©cris des sch√©mas, graphiques
5. INTERACTION: Pose des questions pour v√©rifier la compr√©hension

STRUCTURE D'EXPLICATION:
1. Contextualisation (pourquoi c'est important)
2. D√©finition claire du concept
3. D√©composition en √©tapes simples
4. Exemples pratiques
5. Applications et exercices
6. Liens avec d'autres notions

ADAPTATION AU PROFIL:
- VISUEL: Descriptions d√©taill√©es, sch√©mas mentaux
- AUDITIF: Explications orales, r√©p√©titions
- KINESTH√âSIQUE: Manipulations, exp√©riences
- LOGIQUE: D√©monstrations rigoureuses, preuves

V√âRIFICATION DE COMPR√âHENSION:
- Questions de reformulation
- Exercices d'application imm√©diate
- D√©tection des malentendus
- Ajustement en temps r√©el"""

    def _get_motivation_prompt(self) -> str:
        """Prompt syst√®me pour la motivation"""
        return """Tu es ARIA en mode MOTIVATION. Ton r√¥le est d'inspirer, encourager et maintenir l'engagement de l'√©l√®ve.

STRAT√âGIES MOTIVATIONNELLES:
1. VALORISATION: Reconna√Ætre les efforts et progr√®s
2. OBJECTIFS: Fixer des buts atteignables et stimulants
3. AUTONOMIE: D√©velopper la confiance en soi
4. SENS: Montrer l'utilit√© et les applications
5. D√âFI: Proposer des challenges adapt√©s

TECHNIQUES D'ENCOURAGEMENT:
- C√©l√©brer les petites victoires
- Transformer les erreurs en apprentissages
- Partager des success stories inspirantes
- Rappeler les objectifs √† long terme
- Proposer des d√©fis gamifi√©s

GESTION DU STRESS ET DE L'ANXI√âT√â:
- Techniques de relaxation
- M√©thodes de gestion du temps
- Pr√©paration mentale aux examens
- D√©veloppement de la r√©silience
- Maintien de l'√©quilibre vie/√©tudes

PERSONNALISATION MOTIVATIONNELLE:
- Identifier les sources de motivation personnelles
- Adapter le discours au profil psychologique
- Utiliser les centres d'int√©r√™t de l'√©l√®ve
- Cr√©er des connexions √©motionnelles positives"""

    def _get_document_generation_prompt(self) -> str:
        """Prompt syst√®me pour la g√©n√©ration de documents"""
        return """Tu es ARIA en mode G√âN√âRATION DE DOCUMENTS. Tu cr√©es des supports p√©dagogiques personnalis√©s et de haute qualit√©.

TYPES DE DOCUMENTS:
1. FICHES DE R√âVISION: Synth√®ses structur√©es
2. EXERCICES: Entra√Ænements progressifs
3. CORRIG√âS: Solutions d√©taill√©es et m√©thodiques
4. PLANS DE COURS: S√©quences p√©dagogiques
5. √âVALUATIONS: Tests et examens blancs
6. M√âTHODES: Guides m√©thodologiques

STANDARDS DE QUALIT√â:
- Contenu scientifiquement exact
- Progression p√©dagogique coh√©rente
- Mise en forme claire et a√©r√©e
- Exemples vari√©s et pertinents
- Exercices d'application imm√©diate

PERSONNALISATION:
- Adaptation au niveau de l'√©l√®ve
- Prise en compte du style d'apprentissage
- Int√©gration des objectifs personnels
- R√©f√©rences au programme officiel
- Pr√©paration aux sp√©cificit√©s d'examen

STRUCTURE TYPE:
1. Objectifs d'apprentissage
2. Pr√©requis n√©cessaires
3. D√©veloppement structur√©
4. Exemples et applications
5. Exercices d'entra√Ænement
6. Points cl√©s √† retenir
7. Pour aller plus loin"""

    def _get_quiz_generation_prompt(self) -> str:
        """Prompt syst√®me pour la g√©n√©ration de quiz"""
        return """Tu es ARIA en mode G√âN√âRATION DE QUIZ. Tu cr√©es des √©valuations interactives et formatives.

TYPES DE QUESTIONS:
1. QCM: Questions √† choix multiples
2. VRAI/FAUX: Affirmations √† valider
3. R√âPONSE COURTE: Questions ouvertes br√®ves
4. PROBL√àMES: Exercices de calcul ou raisonnement
5. ANALYSE: Questions de r√©flexion approfondie

NIVEAUX DE DIFFICULT√â:
- FACILE: Connaissances de base, d√©finitions
- MOYEN: Applications directes, m√©thodes
- DIFFICILE: Synth√®se, analyse, cr√©ativit√©
- EXPERT: Probl√®mes complexes, innovation

CRIT√àRES DE QUALIT√â:
- Questions claires et non ambigu√´s
- Distracteurs plausibles (pour QCM)
- Progression logique de difficult√©
- Couverture √©quilibr√©e du programme
- Feedback constructif pour chaque r√©ponse

FORMAT DE SORTIE:
```json
{
  "quiz_id": "unique_id",
  "title": "Titre du quiz",
  "subject": "mati√®re",
  "level": "niveau",
  "duration": "dur√©e estim√©e",
  "questions": [
    {
      "id": "q1",
      "type": "mcq|true_false|short_answer|problem",
      "question": "√ânonc√© de la question",
      "options": ["option1", "option2", "option3", "option4"],
      "correct_answer": "r√©ponse correcte",
      "explanation": "explication d√©taill√©e",
      "difficulty": "easy|medium|hard",
      "points": "nombre de points"
    }
  ]
}
```"""

    async def chat_with_aria(
        self,
        message: str,
        context: ConversationContext,
        student_profile: StudentProfile
    ) -> Dict[str, Any]:
        """Conversation principale avec ARIA"""

        if not self.client:
            return self._simulate_aria_response(message, context, student_profile)

        try:
            # Construction du prompt personnalis√©
            system_prompt = self._build_personalized_prompt(context, student_profile)

            # Historique de conversation
            messages = [{"role": "system", "content": system_prompt}]

            # Ajout de l'historique
            for msg in context.previous_messages[-10:]:  # Garde les 10 derniers messages
                messages.append({
                    "role": msg.get("role", "user"),
                    "content": msg.get("content", "")
                })

            # Message actuel
            messages.append({"role": "user", "content": message})

            # Appel √† l'API OpenAI
            response = await self._make_openai_request(messages, context)

            # Traitement de la r√©ponse
            aria_response = response.choices[0].message.content

            # Analyse de la r√©ponse pour extraire des m√©tadonn√©es
            metadata = self._analyze_response(aria_response, context)

            return {
                "response": aria_response,
                "metadata": metadata,
                "usage": {
                    "prompt_tokens": response.usage.prompt_tokens,
                    "completion_tokens": response.usage.completion_tokens,
                    "total_tokens": response.usage.total_tokens
                },
                "model": response.model,
                "timestamp": datetime.now().isoformat()
            }

        except Exception as e:
            logger.error(f"Erreur lors de la conversation avec ARIA: {e}")
            return self._simulate_aria_response(message, context, student_profile)

    def _build_personalized_prompt(
        self,
        context: ConversationContext,
        student_profile: StudentProfile
    ) -> str:
        """Construit un prompt personnalis√© selon le contexte et le profil"""

        base_prompt = self.system_prompts.get(context.conversation_type, self.system_prompts["tutoring"])

        personalization = f"""
PROFIL DE L'√âL√àVE:
- Nom: {student_profile.name}
- Niveau: {student_profile.level}
- Sp√©cialit√©s: {', '.join(student_profile.specialties)}
- Style d'apprentissage: {student_profile.learning_style}
- Points forts: {', '.join(student_profile.strengths)}
- Points √† am√©liorer: {', '.join(student_profile.weaknesses)}
- Objectifs: {', '.join(student_profile.goals)}

CONTEXTE DE LA SESSION:
- Mati√®re: {context.subject}
- Sujet: {context.topic or 'Non sp√©cifi√©'}
- Niveau de difficult√©: {context.difficulty_level}
- Objectifs d'apprentissage: {', '.join(context.learning_objectives)}
"""

        if context.time_limit:
            personalization += f"- Temps disponible: {context.time_limit} minutes\n"

        return base_prompt + "\n" + personalization

    async def _make_openai_request(self, messages: List[Dict], context: ConversationContext) -> Any:
        """Effectue la requ√™te vers l'API OpenAI"""

        # Param√®tres adaptatifs selon le contexte
        temperature = 0.3 if context.conversation_type == "evaluation" else 0.7
        max_tokens = 2000 if context.time_limit and context.time_limit < 30 else self.max_tokens

        return await asyncio.to_thread(
            self.client.chat.completions.create,
            model=self.model_chat,
            messages=messages,
            temperature=temperature,
            max_tokens=max_tokens,
            top_p=0.9,
            frequency_penalty=0.1,
            presence_penalty=0.1
        )

    def _analyze_response(self, response: str, context: ConversationContext) -> Dict[str, Any]:
        """Analyse la r√©ponse d'ARIA pour extraire des m√©tadonn√©es"""

        metadata = {
            "sentiment": "positive",  # Analyse de sentiment basique
            "complexity": "medium",   # Complexit√© de la r√©ponse
            "topics_covered": [],     # Sujets abord√©s
            "recommendations": [],    # Recommandations g√©n√©r√©es
            "next_steps": [],        # √âtapes suivantes sugg√©r√©es
            "difficulty_assessment": context.difficulty_level
        }

        # Analyse basique du contenu
        if any(word in response.lower() for word in ["excellent", "parfait", "bravo", "f√©licitations"]):
            metadata["sentiment"] = "very_positive"
        elif any(word in response.lower() for word in ["attention", "erreur", "incorrect", "r√©viser"]):
            metadata["sentiment"] = "constructive"

        # D√©tection de recommandations
        if "je recommande" in response.lower() or "je sugg√®re" in response.lower():
            # Extraction basique des recommandations
            lines = response.split('\n')
            for line in lines:
                if any(word in line.lower() for word in ["recommande", "sugg√®re", "conseil"]):
                    metadata["recommendations"].append(line.strip())

        return metadata

    def _simulate_aria_response(
        self,
        message: str,
        context: ConversationContext,
        student_profile: StudentProfile
    ) -> Dict[str, Any]:
        """Simule une r√©ponse d'ARIA quand l'API n'est pas disponible"""

        # R√©ponses simul√©es selon le contexte
        simulated_responses = {
            "tutoring": f"Bonjour {student_profile.name} ! Je comprends que vous travaillez sur {context.subject}. Pouvez-vous me dire o√π vous en √™tes dans votre apprentissage ? Je vais adapter mes explications √† votre style d'apprentissage {student_profile.learning_style}.",

            "evaluation": f"Tr√®s bien {student_profile.name}, commen√ßons cette √©valuation en {context.subject}. Je vais adapter les questions √† votre niveau {student_profile.level}. √ätes-vous pr√™t(e) ?",

            "explanation": f"Excellente question sur {context.topic} ! Laissez-moi vous expliquer cela de mani√®re claire et adapt√©e √† votre profil d'apprentissage {student_profile.learning_style}.",

            "motivation": f"Je vois que vous travaillez dur, {student_profile.name} ! Vos efforts en {context.subject} vont porter leurs fruits. Continuons ensemble vers vos objectifs : {', '.join(student_profile.goals[:2])}."
        }

        response = simulated_responses.get(
            context.conversation_type,
            f"Bonjour {student_profile.name} ! Comment puis-je vous aider aujourd'hui en {context.subject} ?"
        )

        return {
            "response": response,
            "metadata": {
                "sentiment": "positive",
                "complexity": "medium",
                "topics_covered": [context.subject],
                "recommendations": ["Continuez vos efforts !"],
                "next_steps": ["Posez-moi vos questions sp√©cifiques"],
                "difficulty_assessment": context.difficulty_level,
                "simulated": True
            },
            "usage": {"prompt_tokens": 0, "completion_tokens": 0, "total_tokens": 0},
            "model": "simulation",
            "timestamp": datetime.now().isoformat()
        }

    async def generate_document(
        self,
        document_type: str,
        subject: str,
        topic: str,
        student_profile: StudentProfile,
        specifications: Dict[str, Any] = None
    ) -> Dict[str, Any]:
        """G√©n√®re un document p√©dagogique personnalis√©"""

        if not self.client:
            return self._simulate_document_generation(document_type, subject, topic, student_profile)

        try:
            # Construction du prompt pour la g√©n√©ration de document
            prompt = self._build_document_prompt(document_type, subject, topic, student_profile, specifications)

            messages = [
                {"role": "system", "content": self.system_prompts["document_generation"]},
                {"role": "user", "content": prompt}
            ]

            response = await self._make_openai_request(messages, ConversationContext(
                student_id=student_profile.id,
                session_id=f"doc_{datetime.now().timestamp()}",
                subject=subject,
                topic=topic,
                conversation_type="document_generation"
            ))

            document_content = response.choices[0].message.content

            return {
                "content": document_content,
                "type": document_type,
                "subject": subject,
                "topic": topic,
                "student_id": student_profile.id,
                "generated_at": datetime.now().isoformat(),
                "metadata": {
                    "level": student_profile.level,
                    "learning_style": student_profile.learning_style,
                    "personalized": True
                }
            }

        except Exception as e:
            logger.error(f"Erreur lors de la g√©n√©ration de document: {e}")
            return self._simulate_document_generation(document_type, subject, topic, student_profile)

    def _build_document_prompt(
        self,
        document_type: str,
        subject: str,
        topic: str,
        student_profile: StudentProfile,
        specifications: Dict[str, Any] = None
    ) -> str:
        """Construit le prompt pour la g√©n√©ration de document"""

        base_prompt = f"""
G√©n√®re un {document_type} en {subject} sur le sujet "{topic}" pour {student_profile.name}.

PROFIL DE L'√âL√àVE:
- Niveau: {student_profile.level}
- Style d'apprentissage: {student_profile.learning_style}
- Points forts: {', '.join(student_profile.strengths)}
- Points √† am√©liorer: {', '.join(student_profile.weaknesses)}

EXIGENCES:
- Contenu adapt√© au niveau {student_profile.level}
- Style p√©dagogique adapt√© √† un apprenant {student_profile.learning_style}
- Format professionnel et structur√©
- Exemples concrets et exercices d'application
"""

        if specifications:
            base_prompt += f"\nSP√âCIFICATIONS SUPPL√âMENTAIRES:\n"
            for key, value in specifications.items():
                base_prompt += f"- {key}: {value}\n"

        # Sp√©cifications par type de document
        document_specs = {
            "fiche_revision": "Structure: D√©finitions, Formules cl√©s, M√©thodes, Exercices types, Points √† retenir",
            "exercices": "Inclure: √ânonc√©s vari√©s, Solutions d√©taill√©es, Bar√®me de notation, Conseils m√©thodologiques",
            "cours": "Organisation: Introduction, D√©veloppement structur√©, Exemples, Applications, Synth√®se",
            "evaluation": "Composer: Questions progressives, Bar√®me d√©taill√©, Crit√®res d'√©valuation, Correction type"
        }

        if document_type in document_specs:
            base_prompt += f"\n{document_specs[document_type]}"

        return base_prompt

    def _simulate_document_generation(
        self,
        document_type: str,
        subject: str,
        topic: str,
        student_profile: StudentProfile
    ) -> Dict[str, Any]:
        """Simule la g√©n√©ration de document"""

        simulated_content = f"""
# {document_type.replace('_', ' ').title()} - {subject}
## Sujet: {topic}

### Personnalis√© pour {student_profile.name} ({student_profile.level})

**Objectifs d'apprentissage:**
- Comprendre les concepts fondamentaux de {topic}
- Ma√Ætriser les m√©thodes de r√©solution
- D√©velopper l'autonomie en {subject}

**Contenu adapt√© √† votre profil {student_profile.learning_style}:**

1. **Introduction**
   - D√©finition et contexte
   - Importance dans le programme de {student_profile.level}

2. **D√©veloppement**
   - Concepts cl√©s expliqu√©s simplement
   - Exemples concrets et vari√©s
   - M√©thodes de r√©solution √©tape par √©tape

3. **Applications**
   - Exercices d'entra√Ænement progressifs
   - Probl√®mes types du Baccalaur√©at
   - Conseils m√©thodologiques personnalis√©s

4. **Pour aller plus loin**
   - Ressources compl√©mentaires
   - Liens avec vos objectifs: {', '.join(student_profile.goals[:2])}

---
*Document g√©n√©r√© par ARIA - Nexus R√©ussite*
*Adapt√© √† votre profil d'apprentissage {student_profile.learning_style}*
"""

        return {
            "content": simulated_content,
            "type": document_type,
            "subject": subject,
            "topic": topic,
            "student_id": student_profile.id,
            "generated_at": datetime.now().isoformat(),
            "metadata": {
                "level": student_profile.level,
                "learning_style": student_profile.learning_style,
                "personalized": True,
                "simulated": True
            }
        }

    async def generate_quiz(
        self,
        subject: str,
        topic: str,
        difficulty: str,
        num_questions: int,
        student_profile: StudentProfile
    ) -> Dict[str, Any]:
        """G√©n√®re un quiz personnalis√©"""

        if not self.client:
            return self._simulate_quiz_generation(subject, topic, difficulty, num_questions, student_profile)

        try:
            prompt = f"""
G√©n√®re un quiz de {num_questions} questions en {subject} sur "{topic}"
pour un √©l√®ve de {student_profile.level} avec un niveau de difficult√© {difficulty}.

Profil de l'√©l√®ve:
- Style d'apprentissage: {student_profile.learning_style}
- Points forts: {', '.join(student_profile.strengths)}
- Points √† am√©liorer: {', '.join(student_profile.weaknesses)}

Format de sortie JSON requis avec questions vari√©es (QCM, Vrai/Faux, r√©ponses courtes).
"""

            messages = [
                {"role": "system", "content": self.system_prompts["quiz_generation"]},
                {"role": "user", "content": prompt}
            ]

            response = await self._make_openai_request(messages, ConversationContext(
                student_id=student_profile.id,
                session_id=f"quiz_{datetime.now().timestamp()}",
                subject=subject,
                topic=topic,
                difficulty_level=difficulty,
                conversation_type="evaluation"
            ))

            quiz_content = response.choices[0].message.content

            # Tentative de parsing JSON
            try:
                quiz_data = json.loads(quiz_content)
            except json.JSONDecodeError:
                # Fallback vers simulation si le JSON n'est pas valide
                return self._simulate_quiz_generation(subject, topic, difficulty, num_questions, student_profile)

            return {
                "quiz": quiz_data,
                "generated_at": datetime.now().isoformat(),
                "metadata": {
                    "subject": subject,
                    "topic": topic,
                    "difficulty": difficulty,
                    "student_level": student_profile.level,
                    "personalized": True
                }
            }

        except Exception as e:
            logger.error(f"Erreur lors de la g√©n√©ration de quiz: {e}")
            return self._simulate_quiz_generation(subject, topic, difficulty, num_questions, student_profile)

    def _simulate_quiz_generation(
        self,
        subject: str,
        topic: str,
        difficulty: str,
        num_questions: int,
        student_profile: StudentProfile
    ) -> Dict[str, Any]:
        """Simule la g√©n√©ration de quiz"""

        simulated_quiz = {
            "quiz_id": f"quiz_{datetime.now().timestamp()}",
            "title": f"Quiz {subject} - {topic}",
            "subject": subject,
            "topic": topic,
            "level": student_profile.level,
            "difficulty": difficulty,
            "duration": num_questions * 2,  # 2 minutes par question
            "questions": []
        }

        # Questions simul√©es selon la mati√®re
        sample_questions = {
            "mathematiques": [
                {
                    "id": "q1",
                    "type": "mcq",
                    "question": f"Quelle est la d√©riv√©e de la fonction f(x) = x¬≤ + 3x + 2 ?",
                    "options": ["2x + 3", "x¬≤ + 3", "2x + 2", "x + 3"],
                    "correct_answer": "2x + 3",
                    "explanation": "La d√©riv√©e de x¬≤ est 2x, la d√©riv√©e de 3x est 3, et la d√©riv√©e d'une constante est 0.",
                    "difficulty": difficulty,
                    "points": 2
                }
            ],
            "nsi": [
                {
                    "id": "q1",
                    "type": "mcq",
                    "question": "Quelle est la complexit√© temporelle de l'algorithme de tri par insertion ?",
                    "options": ["O(n)", "O(n log n)", "O(n¬≤)", "O(2^n)"],
                    "correct_answer": "O(n¬≤)",
                    "explanation": "Dans le pire cas, le tri par insertion compare chaque √©l√©ment avec tous les pr√©c√©dents.",
                    "difficulty": difficulty,
                    "points": 3
                }
            ]
        }

        # G√©n√©ration des questions selon la mati√®re
        subject_key = subject.lower().replace(" ", "").replace("-", "")
        if subject_key in sample_questions:
            base_questions = sample_questions[subject_key]
        else:
            base_questions = [
                {
                    "id": "q1",
                    "type": "short_answer",
                    "question": f"Expliquez bri√®vement le concept principal de {topic}.",
                    "correct_answer": f"R√©ponse attendue sur {topic}",
                    "explanation": f"Explication d√©taill√©e du concept {topic}.",
                    "difficulty": difficulty,
                    "points": 5
                }
            ]

        # Duplication et adaptation des questions
        for i in range(min(num_questions, 5)):  # Maximum 5 questions simul√©es
            question = base_questions[0].copy()
            question["id"] = f"q{i+1}"
            simulated_quiz["questions"].append(question)

        return {
            "quiz": simulated_quiz,
            "generated_at": datetime.now().isoformat(),
            "metadata": {
                "subject": subject,
                "topic": topic,
                "difficulty": difficulty,
                "student_level": student_profile.level,
                "personalized": True,
                "simulated": True
            }
        }

    async def generate_image(
        self,
        prompt: str,
        style: str = "educational",
        size: str = "1024x1024"
    ) -> Dict[str, Any]:
        """G√©n√®re une image p√©dagogique avec DALL-E"""

        if not self.client:
            return self._simulate_image_generation(prompt, style, size)

        try:
            # Am√©lioration du prompt pour un contexte √©ducatif
            educational_prompt = f"""
{prompt}
Style: {style}, educational illustration, clear and professional,
suitable for French high school students, clean background,
high contrast, pedagogical diagram
"""

            response = await asyncio.to_thread(
                self.client.images.generate,
                model=self.model_image,
                prompt=educational_prompt,
                size=size,
                quality="standard",
                n=1
            )

            image_url = response.data[0].url

            return {
                "image_url": image_url,
                "prompt": educational_prompt,
                "style": style,
                "size": size,
                "generated_at": datetime.now().isoformat(),
                "metadata": {
                    "educational": True,
                    "model": self.model_image
                }
            }

        except Exception as e:
            logger.error(f"Erreur lors de la g√©n√©ration d'image: {e}")
            return self._simulate_image_generation(prompt, style, size)

    def _simulate_image_generation(self, prompt: str, style: str, size: str) -> Dict[str, Any]:
        """Simule la g√©n√©ration d'image"""
        return {
            "image_url": "https://via.placeholder.com/1024x1024/4F46E5/FFFFFF?text=Image+Educative",
            "prompt": prompt,
            "style": style,
            "size": size,
            "generated_at": datetime.now().isoformat(),
            "metadata": {
                "educational": True,
                "simulated": True,
                "model": "simulation"
            }
        }

    async def analyze_student_work(
        self,
        work_content: str,
        subject: str,
        assignment_type: str,
        student_profile: StudentProfile
    ) -> Dict[str, Any]:
        """Analyse le travail d'un √©tudiant et fournit un feedback d√©taill√©"""

        if not self.client:
            return self._simulate_work_analysis(work_content, subject, assignment_type, student_profile)

        try:
            analysis_prompt = f"""
Analyse le travail suivant d'un √©l√®ve de {student_profile.level} en {subject}:

TRAVAIL √Ä ANALYSER:
{work_content}

TYPE D'EXERCICE: {assignment_type}

PROFIL DE L'√âL√àVE:
- Nom: {student_profile.name}
- Points forts: {', '.join(student_profile.strengths)}
- Points √† am√©liorer: {', '.join(student_profile.weaknesses)}
- Style d'apprentissage: {student_profile.learning_style}

ANALYSE DEMAND√âE:
1. √âvaluation de la justesse des r√©ponses
2. Qualit√© du raisonnement et de la m√©thodologie
3. Points positifs √† valoriser
4. Erreurs identifi√©es et leur origine
5. Conseils d'am√©lioration personnalis√©s
6. Note sugg√©r√©e sur 20 avec justification
7. Exercices de rem√©diation recommand√©s

Sois bienveillant mais rigoureux dans ton analyse.
"""

            messages = [
                {"role": "system", "content": self.system_prompts["evaluation"]},
                {"role": "user", "content": analysis_prompt}
            ]

            response = await self._make_openai_request(messages, ConversationContext(
                student_id=student_profile.id,
                session_id=f"analysis_{datetime.now().timestamp()}",
                subject=subject,
                conversation_type="evaluation"
            ))

            analysis = response.choices[0].message.content

            return {
                "analysis": analysis,
                "subject": subject,
                "assignment_type": assignment_type,
                "student_id": student_profile.id,
                "analyzed_at": datetime.now().isoformat(),
                "metadata": {
                    "personalized": True,
                    "student_level": student_profile.level
                }
            }

        except Exception as e:
            logger.error(f"Erreur lors de l'analyse du travail: {e}")
            return self._simulate_work_analysis(work_content, subject, assignment_type, student_profile)

    def _simulate_work_analysis(
        self,
        work_content: str,
        subject: str,
        assignment_type: str,
        student_profile: StudentProfile
    ) -> Dict[str, Any]:
        """Simule l'analyse de travail"""

        simulated_analysis = f"""
# Analyse du travail de {student_profile.name}

## √âvaluation g√©n√©rale
Votre travail en {subject} montre une bonne compr√©hension des concepts de base.

## Points positifs ‚úÖ
- M√©thodologie claire et structur√©e
- Effort visible dans la pr√©sentation
- Raisonnement logique suivi

## Points d'am√©lioration üìà
- Attention aux calculs (quelques erreurs d'inattention)
- D√©velopper davantage les explications
- V√©rifier les unit√©s dans les r√©sultats

## Note sugg√©r√©e: 14/20

## Conseils personnalis√©s
Compte tenu de votre profil d'apprentissage {student_profile.learning_style}, je recommande:
- Plus d'exercices d'application pour consolider
- Utilisation de sch√©mas pour visualiser les concepts
- R√©vision des points faibles identifi√©s: {', '.join(student_profile.weaknesses[:2])}

## Prochaines √©tapes
1. Refaire les exercices similaires
2. Approfondir les notions mal ma√Ætris√©es
3. Pr√©parer les prochains chapitres

Continuez vos efforts, vous √™tes sur la bonne voie ! üéØ
"""

        return {
            "analysis": simulated_analysis,
            "subject": subject,
            "assignment_type": assignment_type,
            "student_id": student_profile.id,
            "analyzed_at": datetime.now().isoformat(),
            "metadata": {
                "personalized": True,
                "student_level": student_profile.level,
                "simulated": True
            }
        }

    def get_usage_statistics(self) -> Dict[str, Any]:
        """Retourne les statistiques d'utilisation de l'API"""
        # En production, ces donn√©es seraient stock√©es en base
        return {
            "total_requests": 0,
            "total_tokens": 0,
            "requests_by_type": {
                "chat": 0,
                "document_generation": 0,
                "quiz_generation": 0,
                "image_generation": 0,
                "work_analysis": 0
            },
            "average_response_time": 0,
            "success_rate": 100,
            "last_updated": datetime.now().isoformat()
        }

# Instance globale du service
openai_service = OpenAIIntegration()

# Fonctions utilitaires pour l'utilisation dans l'application
async def chat_with_aria(message: str, student_id: str, context: Dict = None) -> Dict:
    """Interface simplifi√©e pour le chat avec ARIA"""

    # Profil √©tudiant par d√©faut (√† remplacer par une vraie base de donn√©es)
    default_profile = StudentProfile(
        id=student_id,
        name="√âtudiant",
        level="terminale",
        specialties=["mathematiques", "nsi"],
        learning_style="mixed",
        strengths=["logique", "analyse"],
        weaknesses=["calcul mental", "gestion du temps"],
        goals=["r√©ussir le bac", "int√©grer une CPGE"]
    )

    # Contexte par d√©faut
    default_context = ConversationContext(
        student_id=student_id,
        session_id=context.get("session_id", f"session_{datetime.now().timestamp()}") if context else f"session_{datetime.now().timestamp()}",
        subject=context.get("subject", "g√©n√©ral") if context else "g√©n√©ral",
        topic=context.get("topic") if context else None,
        conversation_type=context.get("type", "tutoring") if context else "tutoring"
    )

    return await openai_service.chat_with_aria(message, default_context, default_profile)

async def generate_personalized_document(
    document_type: str,
    subject: str,
    topic: str,
    student_id: str
) -> Dict:
    """Interface simplifi√©e pour la g√©n√©ration de documents"""

    default_profile = StudentProfile(
        id=student_id,
        name="√âtudiant",
        level="terminale",
        specialties=[subject.lower()],
        learning_style="visual",
        strengths=["compr√©hension", "m√©morisation"],
        weaknesses=["application", "rapidit√©"],
        goals=["ma√Ætriser le programme", "obtenir une bonne note"]
    )

    return await openai_service.generate_document(document_type, subject, topic, default_profile)

async def create_adaptive_quiz(
    subject: str,
    topic: str,
    difficulty: str,
    num_questions: int,
    student_id: str
) -> Dict:
    """Interface simplifi√©e pour la g√©n√©ration de quiz"""

    default_profile = StudentProfile(
        id=student_id,
        name="√âtudiant",
        level="terminale",
        specialties=[subject.lower()],
        learning_style="mixed",
        strengths=["raisonnement"],
        weaknesses=["rapidit√©"],
        goals=["progresser", "r√©ussir"]
    )

    return await openai_service.generate_quiz(subject, topic, difficulty, num_questions, default_profile)

